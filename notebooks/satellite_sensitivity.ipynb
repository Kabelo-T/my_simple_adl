{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "411d3d97-3e51-4cae-b9b0-7413e37bfa08",
   "metadata": {},
   "source": [
    "# Injecting Simulated Satellites to Quantify Dwarf Search Sensitivity in DP0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a9fd0-6977-4018-8c6c-b1f6975eaa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.expandvars('$HOME/software/simple_adl'))\n",
    "import glob\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import healpy as hp\n",
    "import fitsio as fits\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "import simple_adl.survey\n",
    "import simple_adl.isochrone\n",
    "from simple_adl.coordinate_tools import distanceModulusToDistance, angsep\n",
    "from simple_adl.search import write_output, search_by_distance, cut_isochrone_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e1df6c-0956-44aa-8c6f-d8d788497c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmap = sns.cubehelix_palette(start=1.0, rot=-1.0, light=0.8, dark=0.2, hue=1.0, reverse=True, as_cmap=True)\n",
    "cmap = sns.cubehelix_palette(start=3.0, rot=0.5, light=0.6, dark=0.2, hue=1.0, reverse=True, as_cmap=True)\n",
    "#cmap = sns.cubehelix_palette(start=0.0, rot=0.0, light=0.7, dark=0.3, hue=1.0, reverse=True, as_cmap=True)\n",
    "#cmap = sns.cubehelix_palette(start=0.5, rot=0.0, light=0.7, dark=0.3, hue=1.0, reverse=True, as_cmap=True)\n",
    "\n",
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ffae44-aaec-461f-8b76-6b000f81bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnomic(mu_ra, mu_dec, ra, dec):\n",
    "    \"\"\"\n",
    "    https://mathworld.wolfram.com/GnomonicProjection.html\n",
    "    The Gnomic projection is a conformal (angle-preserving) map of \n",
    "    coordinates on a sphere to coordinates on a plane around some central\n",
    "    coordinate.\n",
    "    \"\"\"\n",
    "    mu_ra = np.deg2rad(mu_ra)\n",
    "    mu_dec = np.deg2rad(mu_dec)\n",
    "    ra = np.deg2rad(ra)\n",
    "    dec = np.deg2rad(dec)\n",
    "    \n",
    "    cos_c = np.sin(mu_dec) * np.sin(dec) + np.cos(mu_dec) * np.cos(dec) * np.sin(ra - mu_ra)\n",
    "    x = np.cos(dec) * np.sin(ra - mu_ra) / cos_c\n",
    "    y = (np.cos(mu_dec) * np.sin(dec) - np.sin(mu_dec) *np.cos(dec) * np.cos(ra - mu_ra)) / cos_c\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68842977-3243-4a4c-834a-c486090dba2a",
   "metadata": {},
   "source": [
    "## Load data from RSP TAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be0472e-21f0-4a52-b5a0-d7aaa2586fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.rsp import get_tap_service\n",
    "\n",
    "service = get_tap_service()\n",
    "assert service is not None\n",
    "# assert service.baseurl == \"https://data.lsst.cloud/api/tap\"\n",
    "print(service.baseurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b423682-84c9-4899-8dd4-57701b973e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(service, ra, dec, radius=1.0, gmax=23.5):\n",
    "    \"\"\"Return data queried from Rubin TAP\n",
    "    Parameters\n",
    "    ----------\n",
    "    service : TAP service [str]\n",
    "    ra      : Right Ascension [deg]\n",
    "    dec     : Declination [deg]\n",
    "    radius  : radius around (ra, dec) [deg]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    good_results : pd.Dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Redenning coefficients\n",
    "    R_g = 3.185\n",
    "    R_r = 2.140\n",
    "    R_i = 1.571\n",
    "    \n",
    "    # Define our reference position on the sky and cone radius in arcseconds\n",
    "    # to use in all following examples\n",
    "    coord = SkyCoord(ra=ra*u.degree, dec=dec*u.degree, frame='icrs')\n",
    "    radius = radius * u.deg\n",
    "    \n",
    "    # Quality selection and star--galaxy separation adapted from\n",
    "    # https://github.com/LSSTDESC/DC2-analysis/blob/master/tutorials/object_pandas_stellar_locus.ipynb\n",
    "\n",
    "    snr_threshold = 5\n",
    "    mag_err_threshold = 1/snr_threshold\n",
    "    mag_threshold = 26\n",
    "    \n",
    "    # bright_snr_threshold = 100\n",
    "    # mag_err_threshold = 1/bright_snr_threshold\n",
    "    \n",
    "    safe_max_extended = 1.0\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "            ra, dec,\n",
    "            mag_g, mag_r,\n",
    "            magerr_g, magerr_r,\n",
    "            mag_g - {R_g} AS mag_corrected_g,\n",
    "            mag_r - {R_r} AS mag_corrected_r,\n",
    "            extendedness\n",
    "        FROM dp01_dc2_catalogs.object\n",
    "        WHERE CONTAINS(POINT('ICRS', ra, dec), CIRCLE('ICRS', {coord.ra.value}, {coord.dec.value}, {radius.value})) = 1\n",
    "        AND extendedness < {str(safe_max_extended)}\n",
    "    \"\"\"\n",
    "\n",
    "    job = service.submit_job(query)\n",
    "    job.run()\n",
    "    job.wait(phases=['COMPLETED', 'ERROR'])\n",
    "    async_results = job.fetch_result()\n",
    "    results = async_results.to_table().to_pandas()\n",
    "    job.delete()\n",
    "\n",
    "    good_snr = (results['magerr_g'] < mag_err_threshold) & (results['magerr_r'] < mag_err_threshold)\n",
    "    good_results = results[good_snr]\n",
    "    \n",
    "    return good_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56e73e4-3c86-4b72-b4fa-58a4bf724a12",
   "metadata": {},
   "source": [
    "## Prepare simulated satellites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40231628-80b5-4bed-be0c-6627fd09b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catalog_file(catalog_dir, mc_source_id):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        catalog_dir = string corresponding to directory containing the stellar catalog infiles\n",
    "        mc_source_id = integer corresponding the target MC_SOURCE_ID value\n",
    "    Outputs:\n",
    "        catalog_infile = string corresponding to filename of stellar catalog containing mc_source_id\n",
    "    \"\"\"\n",
    "    catalog_infiles = sorted(glob.glob(catalog_dir + '/*catalog*.fits'))\n",
    "    mc_source_id_array = []\n",
    "    catalog_infile_index_array = []\n",
    "    for ii, catalog_infile in enumerate(catalog_infiles):\n",
    "        mc_source_id_min = int(os.path.basename(catalog_infile).split('.')[0].split('mc_source_id_')[-1].split('-')[0])\n",
    "        mc_source_id_max = int(os.path.basename(catalog_infile).split('.')[0].split('mc_source_id_')[-1].split('-')[1])\n",
    "        assert (mc_source_id_max > mc_source_id_min) & (mc_source_id_min >= 1), 'Found invalue MC_SOURCE_ID values in filenames'\n",
    "        mc_source_id_array.append(np.arange(mc_source_id_min, mc_source_id_max + 1))\n",
    "        catalog_infile_index_array.append(np.tile(ii, 1 + (mc_source_id_max - mc_source_id_min)))\n",
    "\n",
    "    mc_source_id_array = np.concatenate(mc_source_id_array)\n",
    "    catalog_infile_index_array = np.concatenate(catalog_infile_index_array)\n",
    "\n",
    "    assert len(mc_source_id_array) == len(np.unique(mc_source_id_array)), 'Found non-unique MC_SOURCE_ID values in filenames'\n",
    "    assert np.in1d(mc_source_id, mc_source_id_array), 'Requested MC_SOURCE_ID value not among files'\n",
    "    mc_source_id_index = np.nonzero(mc_source_id == mc_source_id_array)[0][0] # second [0] added by smau 7/23/18 to fix incompatiable type bug\n",
    "    return catalog_infiles[catalog_infile_index_array[mc_source_id_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa365a-28be-451e-8f7d-344acda8e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sim_data(sim_dir, mc_source_id):\n",
    "    \"\"\"\n",
    "    Load info for injecting satellite sims\n",
    "    \"\"\"\n",
    "    cat_file = get_catalog_file(sim_dir, mc_source_id)\n",
    "    cat_fits = fits.FITS(cat_file)\n",
    "    w = cat_fits[1].where(f'MC_SOURCE_ID == {mc_source_id}')\n",
    "    try:       \n",
    "        data = cat_fits[1][w]\n",
    "        cat_fits.close()\n",
    "        return data\n",
    "    except IndexError: \n",
    "        print('Array is empty')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e9e912-5b51-40f2-95ff-f544b4e85748",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_dir = '/project/shared/data/satsim/lsst_dc2_v4/'\n",
    "population_file = glob.glob(os.path.join(sim_dir, '*population*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd16faab-5344-4f81-b90f-2a21d4227111",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(population_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82083464-4c7a-4496-80cd-4b75a33707f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_population = fits.read(*population_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da78dab-f423-4b06-8a5a-47a73bf5690d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sim_positions = np.unique(sim_population[['RA', 'DEC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25396a8d-2c61-4d26-b3bd-d6ee62e9816c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.unique(sim_population[['RA', 'DEC']], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2898dbc-adff-46a2-b2da-fa5df55cf8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_population = sim_population.byteswap().newbyteorder()\n",
    "pop = pd.DataFrame(sim_population)\n",
    "print(pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2199463-8c6e-46a7-aa52-1958203c0bb0",
   "metadata": {},
   "source": [
    "### CMD plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f1332b-8887-4eec-ac5e-2ce543f53022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cmd(data, axs):\n",
    "    \"\"\"Plot a color magnitude diagram.\n",
    "    \n",
    "    data: merged_data DataFrame with photometry data\n",
    "    \"\"\"\n",
    "    y = data['mag_g']     #need to check if these are correct columns\n",
    "    x = data['mag_g'] - data['mag_r']\n",
    "    \n",
    "    xlims = [-1, 1.5]  #need to find better way to restrict axes\n",
    "    ylims = [16,28]\n",
    "    axs.set_xlim(xlims); \n",
    "    axs.set_ylim(ylims); \n",
    "    \n",
    "    axs.set_ylabel('$Magnitude (g)$')\n",
    "    axs.set_xlabel('$Color (g-r)$')\n",
    "    \n",
    "    axs.plot(x, y, 'ko', markersize=0.3, alpha=0.3)\n",
    "    axs.invert_yaxis()\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2414c2-0035-40bd-bc78-8444d1317bc4",
   "metadata": {},
   "source": [
    "## Main loop over simulated satellites per position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be0dc5-0615-4d63-8c1e-72fae6040158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear output file\n",
    "f = open(os.path.join('search/results_dir','cal.csv'), 'w')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704e48b5-d473-4580-8f5d-f2721d1f3116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed functionality to only query once\n",
    "fixed_position= [sim_positions[4][0], sim_positions[4][1]]\n",
    "real_data = query(service, fixed_position[0], fixed_position[1], radius=2.0, gmax=23.5)  # pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db349bc-50e1-46a7-9f98-1c93ae44b781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outfile = 'out4.csv'\n",
    "for position in sim_positions:\n",
    "    sim_population_at_position = sim_population[sim_population[['RA', 'DEC']] == position]\n",
    "    for mcid in sim_population_at_position['MC_SOURCE_ID']:\n",
    "        sim_data = load_sim_data(sim_dir, mcid)\n",
    "        if sim_data is not None:\n",
    "            sim_data = sim_data.byteswap().newbyteorder()\n",
    "            sim_data = pd.DataFrame(sim_data)   # convert to pd.DataFrame\n",
    "            c2 = SkyCoord(sim_data['ra'], sim_data['dec'], unit='deg', frame='icrs')\n",
    "            center = SkyCoord(fixed_position[0], fixed_position[1], unit='deg')\n",
    "            d2d = center.separation(c2) \n",
    "            catalogmsk = d2d < 2*u.deg\n",
    "            sim_data = sim_data[catalogmsk]\n",
    "            \n",
    "            if sim_data.empty:\n",
    "                print(\"No satellites to inject into region at ({},{})\".format(fixed_position[0], fixed_position[1]))\n",
    "                continue\n",
    "            \n",
    "            frames = [real_data[real_data.columns[:-1]], sim_data[real_data.columns[:-1]]]\n",
    "            merged_data = pd.concat(frames)  # pd.Dataframe\n",
    "            # perform mag cut on the merged data\n",
    "            good_snr = (merged_data['magerr_g'] < 0.2) & (merged_data['magerr_r'] < 0.2)\n",
    "            merged_data = merged_data[good_snr]\n",
    "            good_mag = (merged_data['mag_g'] < 26) & (merged_data['mag_r'] < 26)\n",
    "            merged_data = merged_data[good_mag]\n",
    "\n",
    "            fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(24, 6))\n",
    "\n",
    "            hb = axs[0].hexbin(*gnomic(*fixed_position, real_data['ra'], real_data['dec']), mincnt=1, cmap=cmap, gridsize=50)\n",
    "            cb = fig.colorbar(hb, ax=axs[0])\n",
    "            # axs[0].scatter(0, 0, c='r', marker='+', s=200)\n",
    "            axs[0].set_title('DC2 Data')\n",
    "            axs[0].set_xlabel(r'$x$')\n",
    "            axs[0].set_ylabel(r'$y$')\n",
    "\n",
    "            hb = axs[1].hexbin(*gnomic(*fixed_position, sim_data['ra'], sim_data['dec']), mincnt=1, cmap=cmap, gridsize=50)\n",
    "            cb = fig.colorbar(hb, ax=axs[1])\n",
    "            # axs[1].scatter(0, 0, c='r', marker='+', s=200)\n",
    "            axs[1].set_title('Simulated Satellite')\n",
    "            axs[1].set_xlabel(r'$x$')\n",
    "            axs[1].set_ylabel(r'$y$')\n",
    "\n",
    "            hb = axs[2].hexbin(*gnomic(*fixed_position, merged_data['ra'], merged_data['dec']), mincnt=1, cmap=cmap, gridsize=50)\n",
    "            cb = fig.colorbar(hb, ax=axs[2])\n",
    "            # axs[2].scatter(0, 0, c='r', marker='+', s=200)\n",
    "            axs[2].set_title('Merged')\n",
    "            axs[2].set_xlabel(r'$x$')\n",
    "            axs[2].set_ylabel(r'$y$')\n",
    "\n",
    "            plot_cmd(merged_data, axs[3])\n",
    "            plt.show()\n",
    "\n",
    "            print('Searching for: MC_SOURCE_ID ', mcid)\n",
    "            with open('search/config.yaml') as ymlfile:\n",
    "                cfg = yaml.load(ymlfile, Loader=yaml.SafeLoader)\n",
    "                survey = simple_adl.survey.Survey(cfg)\n",
    "            ra = fixed_position[0]\n",
    "            dec = fixed_position[1]\n",
    "            region = simple_adl.survey.Region(survey, ra, dec)\n",
    "            region.data = merged_data\n",
    "\n",
    "            # Scan in distance moduli    \n",
    "            distance_modulus_search_array = np.arange(16., survey.catalog['mag_max'], 0.5)\n",
    "\n",
    "            iso_search_array = [simple_adl.isochrone.Isochrone(survey=survey.isochrone['survey'],\n",
    "                                                   band_1=survey.band_1.lower(),\n",
    "                                                   band_2=survey.band_2.lower(),\n",
    "                                                   age=12.0, #survey.isochrone['age'],\n",
    "                                                   metallicity=0.00010, #survey.isochrone['metallicity'],\n",
    "                                                   distance_modulus=distance_modulus)\n",
    "                                for distance_modulus in distance_modulus_search_array]\n",
    "\n",
    "            iso_selection_array = [cut_isochrone_path(region.data[survey.mag_dered_1], \n",
    "                                                  region.data[survey.mag_dered_2],\n",
    "                                                  region.data[survey.mag_err_1],\n",
    "                                                  region.data[survey.mag_err_2],\n",
    "                                                  iso,\n",
    "                                                  survey.catalog['mag_max'],\n",
    "                                                  radius=0.1)\n",
    "                               for iso in iso_search_array]\n",
    "\n",
    "            results = [search_by_distance(survey, region, distance_modulus, iso_sel) for (distance_modulus,iso_sel) in zip(distance_modulus_search_array,iso_selection_array)] \n",
    "            best_ra_peak, best_dec_peak, best_r_peak, best_distance_modulus, n_obs_peak, n_obs_half_peak, n_model_peak, best_sig_peak = 0, 0, 0, 0, 0, 0, 0, 0\n",
    "            for scan in results:\n",
    "                ra_peak_array, dec_peak_array, r_peak_array, sig_peak_array, distance_modulus_array, n_obs_peak_array, n_obs_half_peak_array, n_model_peak_array = np.asarray(scan)\n",
    "                if mcid: \n",
    "                    mc_source_id_array = np.full_like(distance_modulus_array, mcid)\n",
    "                else:\n",
    "                    mc_source_id_array = np.zeros(len(distance_modulus_array))\n",
    "\n",
    "                # Sort peaks according to significance\n",
    "                index_sort = np.argsort(sig_peak_array)[::-1]\n",
    "                ra_peak_array = ra_peak_array[index_sort]\n",
    "                dec_peak_array = dec_peak_array[index_sort]\n",
    "                r_peak_array = r_peak_array[index_sort]\n",
    "                sig_peak_array = sig_peak_array[index_sort]\n",
    "                distance_modulus_array = distance_modulus_array[index_sort]\n",
    "                n_obs_peak_array = n_obs_peak_array[index_sort]\n",
    "                n_obs_half_peak_array = n_obs_half_peak_array[index_sort]\n",
    "                n_model_peak_array = n_model_peak_array[index_sort]\n",
    "                mc_source_id_array = mc_source_id_array[index_sort]\n",
    "\n",
    "\n",
    "\n",
    "                # Collect overlapping peaks\n",
    "                for ii in range(0, len(sig_peak_array)):\n",
    "                    if sig_peak_array[ii] < 0:\n",
    "                        continue\n",
    "                    sep = angsep(ra_peak_array[ii], dec_peak_array[ii], ra_peak_array, dec_peak_array)\n",
    "                    sig_peak_array[(sep < r_peak_array[ii]) & (np.arange(len(sig_peak_array)) > ii)] = -1.\n",
    "                    #sig_peak_array[(sep < 0.5) & (np.arange(len(sig_peak_array)) > ii)] = -1. # 0.5 deg radius\n",
    "\n",
    "                # Prune the list of peaks\n",
    "                ra_peak_array = ra_peak_array[sig_peak_array > 0.]\n",
    "                dec_peak_array = dec_peak_array[sig_peak_array > 0.]\n",
    "                r_peak_array = r_peak_array[sig_peak_array > 0.]\n",
    "                distance_modulus_array = distance_modulus_array[sig_peak_array > 0.]\n",
    "                n_obs_peak_array = n_obs_peak_array[sig_peak_array > 0.]\n",
    "                n_obs_half_peak_array = n_obs_half_peak_array[sig_peak_array > 0.]\n",
    "                n_model_peak_array = n_model_peak_array[sig_peak_array > 0.]\n",
    "                mc_source_id_array = mc_source_id_array[sig_peak_array > 0.]\n",
    "                sig_peak_array = sig_peak_array[sig_peak_array > 0.] # Update the sig_peak_array last!\n",
    "\n",
    "                if sig_peak_array[0] > best_sig_peak:\n",
    "                    best_sig_peak = sig_peak_array[0]\n",
    "                    best_ra_peak = ra_peak_array[0]\n",
    "                    best_dec_peak = dec_peak_array[0]\n",
    "                    best_r_peak = r_peak_array[0]\n",
    "                    best_distance_modulus = distance_modulus_array[0]\n",
    "                    n_obs_peak = n_obs_peak_array[0]\n",
    "                    n_obs_half_peak = n_obs_half_peak_array[0]\n",
    "                    n_model_peak = n_model_peak_array[0]\n",
    "                    mc_source_id = mc_source_id_array[0]\n",
    "\n",
    "                for ii in range(0, len(sig_peak_array)):\n",
    "                    print('{:0.2f} sigma; (RA, Dec) = ({:0.2f}, {:0.2f}); r = {:0.2f} deg; d = {:0.1f}, mu = {:0.2f} mag, mc_source_id: {:0.2f}'.format(sig_peak_array[ii], \n",
    "                             ra_peak_array[ii], \n",
    "                             dec_peak_array[ii], \n",
    "                             r_peak_array[ii],\n",
    "                             distanceModulusToDistance(distance_modulus_array[ii]),\n",
    "                             distance_modulus_array[ii],\n",
    "                             mc_source_id_array[ii]))\n",
    "            del merged_data\n",
    "            # Write output\n",
    "            # there is an error that comes every now and agin that changes the output format\n",
    "        try:\n",
    "            if (len(sig_peak_array) > 0):\n",
    "                write_output(os.path.join('search', survey.output['results_dir']), survey.catalog['nside'], region.pix_center, best_ra_peak, best_dec_peak,\n",
    "                                best_r_peak, best_distance_modulus, \n",
    "                                n_obs_peak, n_obs_half_peak, n_model_peak, \n",
    "                                best_sig_peak, mcid, 0, outfile)\n",
    "            else:\n",
    "                print('No significant hotspots found.')\n",
    "                nan_array = [np.nan]\n",
    "                write_output(os.path.join('search', survey.output['results_dir']), survey.catalog['nside'], region.pix_center,\n",
    "                                 nan_array, nan_array, nan_array, nan_array, \n",
    "                                 nan_array, nan_array, nan_array, nan_array,\n",
    "                                 [mc_source_id], 0, outfile)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            print('Data missing, cannot write to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99a7bd5-ac52-4e33-886a-3a5586e5fcb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calibration\n",
    "# need to consider how we store this information\n",
    "outfile = 'cal.csv'\n",
    "\n",
    "good_snr = (real_data['magerr_g'] < 0.2) & (real_data['magerr_r'] < 0.2)\n",
    "the_data = real_data[good_snr]\n",
    "good_mag = (the_data['mag_g'] < 26) & (the_data['mag_r'] < 26)\n",
    "the_data = the_data[good_mag]\n",
    "\n",
    "with open('search/config.yaml') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=yaml.SafeLoader)\n",
    "    survey = simple_adl.survey.Survey(cfg)\n",
    "    \n",
    "ra = fixed_position[0]\n",
    "dec = fixed_position[1]\n",
    "region = simple_adl.survey.Region(survey, ra, dec)\n",
    "region.data = the_data\n",
    "\n",
    "# Scan in distance moduli    \n",
    "distance_modulus_search_array = np.arange(16., survey.catalog['mag_max'], 0.5)\n",
    "\n",
    "iso_search_array = [simple_adl.isochrone.Isochrone(survey=survey.isochrone['survey'],\n",
    "                                       band_1=survey.band_1.lower(),\n",
    "                                       band_2=survey.band_2.lower(),\n",
    "                                       age=12.0, #survey.isochrone['age'],\n",
    "                                       metallicity=0.00010, #survey.isochrone['metallicity'],\n",
    "                                       distance_modulus=distance_modulus)\n",
    "                    for distance_modulus in distance_modulus_search_array]\n",
    "\n",
    "iso_selection_array = [cut_isochrone_path(region.data[survey.mag_dered_1], \n",
    "                                      region.data[survey.mag_dered_2],\n",
    "                                      region.data[survey.mag_err_1],\n",
    "                                      region.data[survey.mag_err_2],\n",
    "                                      iso,\n",
    "                                      survey.catalog['mag_max'],\n",
    "                                      radius=0.1)\n",
    "                   for iso in iso_search_array]\n",
    "\n",
    "results = [search_by_distance(survey, region, distance_modulus, iso_sel) for (distance_modulus,iso_sel) in zip(distance_modulus_search_array,iso_selection_array)] \n",
    "best_ra_peak, best_dec_peak, best_r_peak, best_distance_modulus, n_obs_peak, n_obs_half_peak, n_model_peak, best_sig_peak = 0, 0, 0, 0, 0, 0, 0, 0\n",
    "\n",
    "for scan in results:\n",
    "    ra_peak_array, dec_peak_array, r_peak_array, sig_peak_array, distance_modulus_array, n_obs_peak_array, n_obs_half_peak_array, n_model_peak_array = np.asarray(scan)\n",
    "    # Sort peaks according to significance\n",
    "    index_sort = np.argsort(sig_peak_array)[::-1]\n",
    "    ra_peak_array = ra_peak_array[index_sort]\n",
    "    dec_peak_array = dec_peak_array[index_sort]\n",
    "    r_peak_array = r_peak_array[index_sort]\n",
    "    sig_peak_array = sig_peak_array[index_sort]\n",
    "    distance_modulus_array = distance_modulus_array[index_sort]\n",
    "    n_obs_peak_array = n_obs_peak_array[index_sort]\n",
    "    n_obs_half_peak_array = n_obs_half_peak_array[index_sort]\n",
    "    n_model_peak_array = n_model_peak_array[index_sort]\n",
    "\n",
    "    # Collect overlapping peaks\n",
    "    for ii in range(0, len(sig_peak_array)):\n",
    "        if sig_peak_array[ii] < 0:\n",
    "            continue\n",
    "        sep = angsep(ra_peak_array[ii], dec_peak_array[ii], ra_peak_array, dec_peak_array)\n",
    "        sig_peak_array[(sep < r_peak_array[ii]) & (np.arange(len(sig_peak_array)) > ii)] = -1.\n",
    "        #sig_peak_array[(sep < 0.5) & (np.arange(len(sig_peak_array)) > ii)] = -1. # 0.5 deg radius\n",
    "\n",
    "    # Prune the list of peaks\n",
    "    ra_peak_array = ra_peak_array[sig_peak_array > 0.]\n",
    "    dec_peak_array = dec_peak_array[sig_peak_array > 0.]\n",
    "    r_peak_array = r_peak_array[sig_peak_array > 0.]\n",
    "    distance_modulus_array = distance_modulus_array[sig_peak_array > 0.]\n",
    "    n_obs_peak_array = n_obs_peak_array[sig_peak_array > 0.]\n",
    "    n_obs_half_peak_array = n_obs_half_peak_array[sig_peak_array > 0.]\n",
    "    n_model_peak_array = n_model_peak_array[sig_peak_array > 0.]\n",
    "    sig_peak_array = sig_peak_array[sig_peak_array > 0.] # Update the sig_peak_array last!\n",
    "\n",
    "    if sig_peak_array[0] > best_sig_peak:\n",
    "        best_sig_peak = sig_peak_array[0]\n",
    "        best_ra_peak = ra_peak_array[0]\n",
    "        best_dec_peak = dec_peak_array[0]\n",
    "        best_r_peak = r_peak_array[0]\n",
    "        best_distance_modulus = distance_modulus_array[0]\n",
    "        n_obs_peak = n_obs_peak_array[0]\n",
    "        n_obs_half_peak = n_obs_half_peak_array[0]\n",
    "        n_model_peak = n_model_peak_array[0]\n",
    "        \n",
    "    for ii in range(0, len(sig_peak_array)):\n",
    "        print('{:0.2f} sigma; (RA, Dec) = ({:0.2f}, {:0.2f}); r = {:0.2f} deg; d = {:0.1f}, mu = {:0.2f} mag'.format(sig_peak_array[ii], \n",
    "                 ra_peak_array[ii], \n",
    "                 dec_peak_array[ii], \n",
    "                 r_peak_array[ii],\n",
    "                 distanceModulusToDistance(distance_modulus_array[ii]),\n",
    "                 distance_modulus_array[ii]))\n",
    "\n",
    "# Write output\n",
    "\n",
    "try:\n",
    "    if (len(sig_peak_array) > 0):\n",
    "        write_output(os.path.join('search', survey.output['results_dir']), survey.catalog['nside'], region.pix_center, best_ra_peak, best_dec_peak,\n",
    "                        best_r_peak, best_distance_modulus, \n",
    "                        n_obs_peak, n_obs_half_peak, n_model_peak, \n",
    "                        best_sig_peak, 0, 0, outfile)\n",
    "    else:\n",
    "        print('No significant hotspots found.')\n",
    "        nan_array = [np.nan]\n",
    "        write_output(os.path.join('search', survey.output['results_dir']), survey.catalog['nside'], region.pix_center,\n",
    "                         nan_array, nan_array, nan_array, nan_array, \n",
    "                         nan_array, nan_array, nan_array, nan_array,\n",
    "                         [0], 0, outfile)\n",
    "except Exception as e: \n",
    "    print(e)\n",
    "    print('Data missing, cannot write to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e7d75d-d2d1-45af-a24e-196477278332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduce the fig 9 rom the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a76805-8d7e-47e8-b3dd-5e9104897c97",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# original\n",
    "i = 0\n",
    "for position in sim_positions:\n",
    "    if i > 10:\n",
    "        break\n",
    "    else:\n",
    "        sim_population_at_position = sim_population[sim_population[['RA', 'DEC']] == position]\n",
    "        real_data = query(service, position[0], position[1], radius=2.0, gmax=23.5)  # pd.DataFrame\n",
    "        sim_data = load_sim_data(sim_dir, sim_population_at_position['MC_SOURCE_ID'].item()) # np.ndarray, .item() only retrieves first record \n",
    "        if sim_data is not None:\n",
    "            # to filter sim_data to only those within real_data region\n",
    "            sim_data = sim_data.byteswap().newbyteorder()            # to deal with data that were created on a machine with a different byte order than the one on which you are running Python\n",
    "            sim_data = pd.DataFrame(sim_data)   # convert to pd.DataFrame\n",
    "            c2 = SkyCoord(sim_data['ra'], sim_data['dec'], unit='deg', frame='icrs')\n",
    "            center = SkyCoord(position[0], position[1], unit='deg')\n",
    "            d2d = center.separation(c2) \n",
    "            catalogmsk = d2d < 2*u.deg\n",
    "            sim_data = sim_data[catalogmsk]\n",
    "\n",
    "            frames = [real_data[real_data.columns[:-1]], sim_data[real_data.columns[:-1]]]\n",
    "            merged_data = pd.concat(frames)  # pd.Dataframe\n",
    "            good_snr = (merged_data['magerr_g'] < 0.2) & (merged_data['magerr_r'] < 0.2)          # perform mag cut on the merged data\n",
    "            merged_data = merged_data[good_snr]\n",
    "            good_mag = (merged_data['mag_g'] < 26) & (merged_data['mag_r'] < 26)\n",
    "            merged_data = merged_data[good_mag]\n",
    "\n",
    "            fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(24, 6))\n",
    "\n",
    "            hb = axs[0].hexbin(*gnomic(*position, real_data['ra'], real_data['dec']), mincnt=1, cmap=cmap, gridsize=50)\n",
    "            cb = fig.colorbar(hb, ax=axs[0])\n",
    "            # axs[0].scatter(0, 0, c='r', marker='+', s=200)\n",
    "            axs[0].set_title('DC2 Data')\n",
    "            axs[0].set_xlabel(r'$x$')\n",
    "            axs[0].set_ylabel(r'$y$')\n",
    "\n",
    "            hb = axs[1].hexbin(*gnomic(*position, sim_data['ra'], sim_data['dec']), mincnt=1, cmap=cmap, gridsize=50)\n",
    "            cb = fig.colorbar(hb, ax=axs[1])\n",
    "            # axs[1].scatter(0, 0, c='r', marker='+', s=200)\n",
    "            axs[1].set_title('Simulated Satellite')\n",
    "            axs[1].set_xlabel(r'$x$')\n",
    "            axs[1].set_ylabel(r'$y$')\n",
    "\n",
    "            hb = axs[2].hexbin(*gnomic(*position, merged_data['ra'], merged_data['dec']), mincnt=1, cmap=cmap, gridsize=50)\n",
    "            cb = fig.colorbar(hb, ax=axs[2])\n",
    "            # axs[2].scatter(0, 0, c='r', marker='+', s=200)\n",
    "            axs[2].set_title('Merged')\n",
    "            axs[2].set_xlabel(r'$x$')\n",
    "            axs[2].set_ylabel(r'$y$')\n",
    "\n",
    "            plot_cmd(merged_data, axs[3])\n",
    "            plt.show()\n",
    "    i +=1\n",
    "        #break #for testing purposes, we don't want to run the full loop\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
